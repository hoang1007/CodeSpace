{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoang1007/CodeSpace/blob/master/mnist_simple_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kquPOuR3e0Ca",
        "outputId": "1cedc8f6-67eb-46af-932a-e5ef01adfa7c"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "qC-K-AvjUUOZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import statistics\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzqRDWPCUUOc"
      },
      "source": [
        "# Implemet các model CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QKRrOkBUUOe",
        "outputId": "83a98e79-6a73-41e8-9819-5ab4623f7b62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channel, out_channels, kernel_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channel, out_channels, kernel_size)\n",
        "\n",
        "        self.batch_norm = nn.BatchNorm2d(out_channels)\n",
        "    \n",
        "    def forward(self, x):    \n",
        "        x = self.conv(x)\n",
        "        x = self.batch_norm(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "ConvBlock(3, 32, 3)(torch.rand((1, 3, 28, 28))).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dGg_bOIUUOg"
      },
      "source": [
        "## Model chỉ bao gồm các convolution block"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qrnaBHjUUOg",
        "outputId": "29103a46-378c-4b64-e651-301b9a0d0bfe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "class SingleCNN(nn.Module):\n",
        "    def __init__(self, in_dim, out_dim, in_channel, block_channels, kernel_size):\n",
        "        '''\n",
        "        in_dim: int len of one dimensional of 2D image\n",
        "        out_dim: int dimension of output\n",
        "        '''\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(*[\n",
        "            ConvBlock(\n",
        "                in_channel if i == 0 else block_channels[i - 1],\n",
        "                block_channels[i],\n",
        "                kernel_size\n",
        "            ) for i in range(len(block_channels))\n",
        "        ])\n",
        "\n",
        "        self.linear = self._linear_block(in_dim, out_dim, block_channels, kernel_size)\n",
        "        self.batch_norm = nn.BatchNorm1d(out_dim)\n",
        "    \n",
        "    def _linear_block(self, in_dim, out_dim, block_channels, kernel_size):\n",
        "        conv_out_dim = in_dim - (kernel_size - 1) * len(block_channels)\n",
        "        linear_input_dim = conv_out_dim**2 * block_channels[-1]\n",
        "\n",
        "        linear = nn.Linear(linear_input_dim, out_dim)\n",
        "        return linear\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        \n",
        "        # conv_outputs.shape == (batch_size, channels, img_size, img_size)\n",
        "        conv_outputs = self.conv_blocks(x)\n",
        "        conv_outputs = torch.flatten(conv_outputs, start_dim=1)\n",
        "\n",
        "        linear_outputs = self.linear(conv_outputs)\n",
        "        linear_outputs = self.batch_norm(linear_outputs)\n",
        "\n",
        "        return linear_outputs\n",
        "\n",
        "\n",
        "SingleCNN(28, 10, 3, [5, 7], 3)(torch.rand((2, 3, 28, 28))).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pjdo712BUUOh"
      },
      "source": [
        "# Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv-1iq4TUUOi"
      },
      "source": [
        "## Majority Voting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXlJ3vJ3UUOi",
        "outputId": "83d51693-c9e9-4c1c-c9e1-b621e50d70fa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([3, 0, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def arg_max_frequency(inputs: torch.tensor):\n",
        "    '''\n",
        "    inputs: vector\n",
        "    '''\n",
        "    freq = {}\n",
        "\n",
        "    for arg in inputs:\n",
        "        if arg.item() in freq:\n",
        "            freq[arg.item()] += 1\n",
        "        else:\n",
        "            freq[arg.item()] = 1\n",
        "\n",
        "    max_freq = 0\n",
        "    args_max = []\n",
        "\n",
        "    for arg in freq:\n",
        "        if max_freq == freq[arg]:\n",
        "            args_max.append(arg)\n",
        "        elif max_freq < freq[arg]:\n",
        "            max_freq = freq[arg]\n",
        "            args_max.clear()\n",
        "\n",
        "            args_max.append(arg)\n",
        "\n",
        "    return random.choice(args_max)\n",
        "\n",
        "def majority_voting(*outputs):\n",
        "    '''\n",
        "    output.shape == (batch_size, num_classes)\n",
        "    '''\n",
        "\n",
        "    # outputs.shape == (num_predict, batch_size)\n",
        "    outputs = torch.stack([torch.argmax(output, dim=-1) for output in outputs])\n",
        "    outputs = outputs.transpose(0, 1) # (batch_size, num_predict)\n",
        "\n",
        "    votings = torch.tensor([arg_max_frequency(output) for output in outputs])\n",
        "\n",
        "    return votings.type_as(outputs)\n",
        "\n",
        "majority_voting(\n",
        "    torch.rand((5, 4)),\n",
        "    torch.rand((5, 4)),\n",
        "    torch.rand((5, 4))\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKKWdu_ZUUOj"
      },
      "source": [
        "## Setup auto recovering model and training state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "MIqnPgsbUUOk"
      },
      "outputs": [],
      "source": [
        "class IModel(nn.Module):\n",
        "    def __init__(self, model_name=None):\n",
        "        super().__init__()\n",
        "        self.device = \"cpu\"\n",
        "        self._model_name = model_name\n",
        "        self._state = {}\n",
        "\n",
        "    def configure_optimizers(self, *args, **kwargs):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def training_epoch_end(self, train_outputs, epoch):\n",
        "        pass\n",
        "\n",
        "    def validation_epoch_end(self, val_outputs, epoch):\n",
        "        pass\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def restore(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @property\n",
        "    def state(self):\n",
        "        return self._state\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return self._model_name\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return super().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "2utnG7GdUUOk"
      },
      "outputs": [],
      "source": [
        "class Trainer:\n",
        "    def __init__(self, checkpoint_dir, restore_if_available=True, update_bar_fraction=.02):\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        self.restore_if_available = restore_if_available\n",
        "        self.update_bar_fraction = update_bar_fraction\n",
        "\n",
        "    def fit(self, model: IModel, train_dataloader, val_dataloader, epochs, device=\"cpu\"):\n",
        "        model_checkpoint = os.path.join(self.checkpoint_dir, model.name)\n",
        "        \n",
        "        pre_state = self._get_previous_state(model_checkpoint) \\\n",
        "            if self.restore_if_available else None\n",
        "\n",
        "        if pre_state is not None:\n",
        "            print(\"Restoring from last session\")\n",
        "\n",
        "            model.restore(pre_state[\"model_state\"])\n",
        "            start_epoch = pre_state[\"epoch\"]\n",
        "            optimizer = pre_state[\"optimizer\"]\n",
        "            scheduler = pre_state[\"scheduler\"]\n",
        "        else:\n",
        "            start_epoch = 1\n",
        "            optimizer, scheduler = model.configure_optimizers()\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # Run val test on the first run\n",
        "        if pre_state is None:\n",
        "          self._val_per_epoch(model, val_dataloader, 0)\n",
        "        \n",
        "        for epoch in range(start_epoch, epochs + 1):\n",
        "            self._train_per_epoch(model, train_dataloader, optimizer, scheduler, epoch)\n",
        "\n",
        "            self._val_per_epoch(model, val_dataloader, epoch)\n",
        "\n",
        "            training_state = {\n",
        "                \"model_state\": model.state,\n",
        "                \"epoch\": epoch,\n",
        "                \"optimizer\": optimizer,\n",
        "                \"scheduler\": scheduler\n",
        "            }\n",
        "\n",
        "            if pre_state is None or epoch >= pre_state[\"epoch\"]:\n",
        "              self._save_state(model_checkpoint, training_state)\n",
        "            else:\n",
        "              print(f\"\"\"Skip backup model state on epoch {epoch}\n",
        "                          since it's lower than backed up model\"\"\")\n",
        "                                    \n",
        "\n",
        "    def _train_per_epoch(self, model: IModel, train_dataloader, optimizer, scheduler, epoch):\n",
        "        model.train()\n",
        "        train_outputs = []\n",
        "\n",
        "        update_bar_step = math.ceil(len(train_dataloader) * self.update_bar_fraction)\n",
        "\n",
        "        with tqdm(train_dataloader, unit='batch') as training_bar:\n",
        "            training_bar.set_description(f\"Epoch {epoch}\")\n",
        "\n",
        "            loss_log = []\n",
        "\n",
        "            for idx, batch in enumerate(training_bar):\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                train_output = model.training_step(batch, idx)\n",
        "\n",
        "                train_outputs.append(train_output)\n",
        "\n",
        "                loss = train_output[0] if isinstance(train_output, tuple) else train_output\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                loss_log.append(loss.item())\n",
        "                \n",
        "                if idx % update_bar_step == 0:\n",
        "                    training_bar.set_postfix(loss=statistics.mean(loss_log))\n",
        "                    loss_log.clear()\n",
        "            scheduler.step()\n",
        "\n",
        "            model.training_epoch_end(train_outputs, epoch)\n",
        "\n",
        "    def _val_per_epoch(self, model: IModel, val_dataloader, epoch):\n",
        "        model.eval()\n",
        "\n",
        "        val_outputs = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for idx, batch in enumerate(val_dataloader):\n",
        "                val_output = model.validation_step(batch, idx)\n",
        "\n",
        "                val_outputs.append(val_output)\n",
        "\n",
        "            model.validation_epoch_end(val_outputs, epoch)\n",
        "\n",
        "    def _get_previous_state(self, filepath):\n",
        "        if os.path.exists(filepath):\n",
        "            with open(filepath, \"rb\") as f:\n",
        "                pre_state = pickle.load(f)\n",
        "        else:\n",
        "            pre_state = None\n",
        "\n",
        "        return pre_state\n",
        "\n",
        "    def _save_state(self, filepath, state):\n",
        "        with open(filepath, \"wb\") as f:\n",
        "            pickle.dump(state, f, pickle.HIGHEST_PROTOCOL)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_wcpO3IUUOm"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "alSueZHeUUOn"
      },
      "outputs": [],
      "source": [
        "class SingleModel(IModel):\n",
        "    def __init__(self, block_channels, kernel_size, model_name):\n",
        "        super().__init__(model_name)\n",
        "\n",
        "        self.random_affine = transforms.RandomAffine(MAX_ROTATION_DEGREE, MAX_TRANSLATION_FRACTION)\n",
        "\n",
        "        self.cnn = SingleCNN(IMG_SIZE, N_DIGITS, 1, block_channels, kernel_size)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.cnn(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "\n",
        "        imgs = imgs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        for i in range(imgs.size(0)):\n",
        "            imgs[i] = self.random_affine(imgs[i])\n",
        "        \n",
        "        logits = self(imgs) # (batch_size, n_digits)\n",
        "\n",
        "        loss = F.cross_entropy(logits, labels)\n",
        "\n",
        "        return loss, logits, labels\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        imgs, labels = batch\n",
        "\n",
        "        imgs = imgs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        logits = self(imgs) # (batch_size, n_digits)\n",
        "\n",
        "        return logits, labels\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.Adam(self.parameters(), LR, weight_decay=WEIGHT_DECAY)\n",
        "        scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=EXPO_GAMMA)\n",
        "\n",
        "        return optimizer, scheduler\n",
        "\n",
        "    def validation_epoch_end(self, val_outputs, epoch):\n",
        "        num_correct = 0\n",
        "        num_labels = 0\n",
        "\n",
        "        for logits, labels in val_outputs:\n",
        "            predicted = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_correct += torch.sum(predicted == labels).item()\n",
        "            num_labels += predicted.size(0)\n",
        "\n",
        "        accur = round(num_correct / num_labels, 2)\n",
        "\n",
        "        if \"val_accur\" in self._state:\n",
        "            self._state[\"val_accur\"].append(accur)\n",
        "        else:\n",
        "            self._state[\"val_accur\"] = [accur]\n",
        "\n",
        "        print(f\"Accuracy on epoch {epoch}:\", num_correct / num_labels)\n",
        "\n",
        "    def training_epoch_end(self, training_outputs, epoch):\n",
        "        num_correct = 0\n",
        "        num_labels = 0\n",
        "\n",
        "        for _, logits, labels in training_outputs:\n",
        "            predicted = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_correct += torch.sum(predicted == labels).item()\n",
        "            num_labels += predicted.size(0)\n",
        "\n",
        "        accur = round(num_correct / num_labels, 2)\n",
        "\n",
        "        # backup state dict\n",
        "        self._state[\"state_dict\"] = self.state_dict()\n",
        "        \n",
        "        if \"train_accur\" in self._state:\n",
        "            self._state[\"train_accur\"].append(accur)\n",
        "        else:\n",
        "            self._state[\"train_accur\"] = [accur]\n",
        "\n",
        "    def restore(self, state):\n",
        "        self.load_state_dict(state[\"state_dict\"])\n",
        "        self._state = state"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 28\n",
        "N_DIGITS = 10\n",
        "MAX_ROTATION_DEGREE = 20\n",
        "MAX_TRANSLATION_FRACTION = (0.2, 0.2)\n",
        "LR = 1e-3\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EXPO_GAMMA = 0.999\n",
        "BATCH_SIZE = 120\n",
        "EPOCHS = 100\n",
        "N_MODEL = 20\n",
        "CHECKPOINT_DIR = \"/content/drive/Shareddrives/colab/mnist_checkpoint/\""
      ],
      "metadata": {
        "id": "P24iDE3keYyv"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = MNIST(\".data\", train=True, transform=transforms.ToTensor(), download=True)\n",
        "val_data = MNIST(\".data\", train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "oNPFQjhNF810"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_data, batch_size=BATCH_SIZE)\n",
        "val_dataloader = DataLoader(val_data, batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "8P0t9T2-hC-s"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m3_models = [\n",
        "  SingleModel([16 * (i + 1) for i in range(1, 10 + 1)],\n",
        "              3, f\"M3_{k}\")\n",
        "    for k in range(N_MODEL)\n",
        "]\n",
        "\n",
        "m5_models = [\n",
        "  SingleModel([32 * i for i in range(1, 5 + 1)],\n",
        "              5, f\"M5_{k}\")\n",
        "    for k in range(N_MODEL)\n",
        "]\n",
        "\n",
        "m7_models = [\n",
        "  SingleModel([48 * i for i in range(1, 4 + 1)],\n",
        "              7, f\"M7_{k}\")\n",
        "    for k in range(N_MODEL)\n",
        "]"
      ],
      "metadata": {
        "id": "8bQgI7H8fMUy"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xh0wBXIKUUOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c59742-ce4c-4f66-81ab-7d1ab2da1bdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on epoch 0: 0.1135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1:  36%|███▌      | 178/500 [00:40<01:12,  4.41batch/s, loss=0.476]"
          ]
        }
      ],
      "source": [
        "# Train m3 models\n",
        "\n",
        "for model in m3_models:\n",
        "  trainer = Trainer(CHECKPOINT_DIR)\n",
        "\n",
        "  trainer.fit(model, train_dataloader, val_dataloader,\n",
        "              epochs=EPOCHS, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train m5 models\n",
        "\n",
        "for model in m5_models:\n",
        "  trainer = Trainer(CHECKPOINT_DIR)\n",
        "\n",
        "  trainer.fit(model, train_dataloader, val_dataloader,\n",
        "              epochs=EPOCHS, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "A-cy-eRYhdle"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train m7 models\n",
        "\n",
        "for model in m7_models:\n",
        "  trainer = Trainer(CHECKPOINT_DIR)\n",
        "\n",
        "  trainer.fit(model, train_dataloader, val_dataloader,\n",
        "              epochs=EPOCHS, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Rc9FZK1ihgaH"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3.8.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "mnist_simple_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}